# AMD AI Server Stack - Pre-built Images Version
# Use this if you want to skip building and use Docker Hub images
#
# Usage: docker compose -f docker-compose.hub.yml up -d
#
# Images are built and published via GitHub Actions from this repo.
# Source: https://github.com/danielrosehill/AMD-AI-Server

services:
  # ==========================================================================
  # CORE: Ollama LLM Server
  # ==========================================================================
  ollama:
    image: ollama/ollama:rocm
    container_name: ollama-rocm
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    environment:
      - HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION:-11.0.1}
      - ROCM_PATH=${ROCM_PATH:-/opt/rocm}
      - HIP_VISIBLE_DEVICES=${HIP_VISIBLE_DEVICES:-0}
    volumes:
      - ${OLLAMA_MODELS:-./models/ollama}:/root/.ollama
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - "44"   # video
      - "992"  # render
    security_opt:
      - seccomp:unconfined
    ipc: host
    networks:
      - ai-stack

  # ==========================================================================
  # STT: Whisper Speech-to-Text (Pre-built)
  # ==========================================================================
  whisper:
    image: danielrosehill/amd-ai-whisper:latest
    container_name: whisper-rocm
    restart: unless-stopped
    ports:
      - "${WHISPER_PORT:-9000}:9000"
    environment:
      - HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION:-11.0.1}
      - ROCM_PATH=${ROCM_PATH:-/opt/rocm}
      - HIP_VISIBLE_DEVICES=${HIP_VISIBLE_DEVICES:-0}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3-turbo}
      - WHISPER_LANGUAGE=${WHISPER_LANGUAGE:-}
    volumes:
      - ${STT_MODELS:-./models/stt}:/root/.cache/whisper
      - ./uploads:/app/uploads
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - "44"   # video
      - "992"  # render
    security_opt:
      - seccomp:unconfined
    ipc: host
    networks:
      - ai-stack

  # ==========================================================================
  # TTS: Chatterbox Text-to-Speech (Pre-built)
  # https://github.com/devnen/Chatterbox-TTS-Server
  # ==========================================================================
  chatterbox:
    image: danielrosehill/amd-ai-chatterbox:latest
    container_name: chatterbox-tts
    restart: unless-stopped
    ports:
      - "${TTS_PORT:-8880}:8004"
    environment:
      - HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION:-11.0.1}
      - HF_HUB_ENABLE_HF_TRANSFER=1
    volumes:
      - ${TTS_VOICES:-./stacks/chatterbox/data/voices}:/app/voices
      - ${TTS_REFERENCE_AUDIO:-./stacks/chatterbox/data/reference_audio}:/app/reference_audio
      - ${TTS_OUTPUTS:-./stacks/chatterbox/data/outputs}:/app/outputs
      - ./stacks/chatterbox/data/logs:/app/logs
      - ./stacks/chatterbox/config.yaml:/app/config.yaml
      - chatterbox_hf_cache:/app/hf_cache
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - "44"   # video
      - "992"  # render
    security_opt:
      - seccomp:unconfined
    ipc: host
    shm_size: 8g
    networks:
      - ai-stack

  # ==========================================================================
  # MANAGEMENT: Control Panel (Pre-built)
  # ==========================================================================
  control-panel:
    image: danielrosehill/amd-ai-control-panel:latest
    container_name: ai-control-panel
    restart: unless-stopped
    ports:
      - "${CONTROL_PANEL_PORT:-8090}:8090"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./docker-compose.hub.yml:/app/docker-compose.yml:ro
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME:-amd-ai-server}
    networks:
      - ai-stack

volumes:
  chatterbox_hf_cache:
    name: chatterbox_hf_cache

networks:
  ai-stack:
    name: ${DOCKER_NETWORK:-ai-stack}
    driver: bridge
